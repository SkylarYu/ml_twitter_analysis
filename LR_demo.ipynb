{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import my_globals\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from utils import get_sub_featured_datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hisky\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>weekday_Mon</th>\n",
       "      <th>weekday_Tue</th>\n",
       "      <th>weekday_Wed</th>\n",
       "      <th>weekday_Thu</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_ð²ñ</th>\n",
       "      <th>tfidf_ðµð³ð</th>\n",
       "      <th>tfidf_ðºð¾ð²ñ</th>\n",
       "      <th>tfidf_ðºñ</th>\n",
       "      <th>tfidf_ð¼ð</th>\n",
       "      <th>tfidf_ð½ð</th>\n",
       "      <th>tfidf_ð¾</th>\n",
       "      <th>tfidf_ð¾ð¼</th>\n",
       "      <th>tfidf_øµø</th>\n",
       "      <th>tfidf_ø¹</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000570</td>\n",
       "      <td>4</td>\n",
       "      <td>1880006855</td>\n",
       "      <td>Thu May 21 23:48:34 PDT 2009</td>\n",
       "      <td>JohnnyEugenio2</td>\n",
       "      <td>Omgosh I put my phone back on the hook so the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>991406</td>\n",
       "      <td>4</td>\n",
       "      <td>1835115440</td>\n",
       "      <td>Mon May 18 05:10:48 PDT 2009</td>\n",
       "      <td>BalaSN</td>\n",
       "      <td>leavin ma office</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1534391</td>\n",
       "      <td>4</td>\n",
       "      <td>2178760886</td>\n",
       "      <td>Mon Jun 15 08:10:05 PDT 2009</td>\n",
       "      <td>eltorgie</td>\n",
       "      <td>thunder!  ... 399/1000 words</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1426117</td>\n",
       "      <td>4</td>\n",
       "      <td>2059166942</td>\n",
       "      <td>Sat Jun 06 16:22:57 PDT 2009</td>\n",
       "      <td>naughtymeg</td>\n",
       "      <td>@chasesterling guess its just me and you!!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120705</td>\n",
       "      <td>0</td>\n",
       "      <td>1833295442</td>\n",
       "      <td>Sun May 17 22:51:09 PDT 2009</td>\n",
       "      <td>Rachel_Butts</td>\n",
       "      <td>@zeneth7 Keen-o! I'm gonna miss you too  I'm g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15958 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  target         ids                          date            user  \\\n",
       "0  1000570       4  1880006855  Thu May 21 23:48:34 PDT 2009  JohnnyEugenio2   \n",
       "1   991406       4  1835115440  Mon May 18 05:10:48 PDT 2009          BalaSN   \n",
       "2  1534391       4  2178760886  Mon Jun 15 08:10:05 PDT 2009        eltorgie   \n",
       "3  1426117       4  2059166942  Sat Jun 06 16:22:57 PDT 2009      naughtymeg   \n",
       "4   120705       0  1833295442  Sun May 17 22:51:09 PDT 2009    Rachel_Butts   \n",
       "\n",
       "                                                text  weekday_Mon  \\\n",
       "0  Omgosh I put my phone back on the hook so the ...          0.0   \n",
       "1                                  leavin ma office           1.0   \n",
       "2                       thunder!  ... 399/1000 words          1.0   \n",
       "3        @chasesterling guess its just me and you!!           0.0   \n",
       "4  @zeneth7 Keen-o! I'm gonna miss you too  I'm g...          0.0   \n",
       "\n",
       "   weekday_Tue  weekday_Wed  weekday_Thu  ...  tfidf_ð²ñ  tfidf_ðµð³ð  \\\n",
       "0          0.0          0.0          1.0  ...        0.0          0.0   \n",
       "1          0.0          0.0          0.0  ...        0.0          0.0   \n",
       "2          0.0          0.0          0.0  ...        0.0          0.0   \n",
       "3          0.0          0.0          0.0  ...        0.0          0.0   \n",
       "4          0.0          0.0          0.0  ...        0.0          0.0   \n",
       "\n",
       "   tfidf_ðºð¾ð²ñ tfidf_ðºñ tfidf_ð¼ð  tfidf_ð½ð  tfidf_ð¾  tfidf_ð¾ð¼  \\\n",
       "0            0.0       0.0       0.0        0.0       0.0         0.0   \n",
       "1            0.0       0.0       0.0        0.0       0.0         0.0   \n",
       "2            0.0       0.0       0.0        0.0       0.0         0.0   \n",
       "3            0.0       0.0       0.0        0.0       0.0         0.0   \n",
       "4            0.0       0.0       0.0        0.0       0.0         0.0   \n",
       "\n",
       "   tfidf_øµø  tfidf_ø¹  \n",
       "0        0.0       0.0  \n",
       "1        0.0       0.0  \n",
       "2        0.0       0.0  \n",
       "3        0.0       0.0  \n",
       "4        0.0       0.0  \n",
       "\n",
       "[5 rows x 15958 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"/\".join([my_globals.DATA_DIR, my_globals.MAIN_DATA_NAME])\n",
    "data = get_sub_featured_datasets(size = 5000, random_seed=4)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-token features:\n",
      "['weekday_Mon', 'weekday_Tue', 'weekday_Wed', 'weekday_Thu', 'weekday_Fri', 'weekday_Sat', 'weekday_Sun', 'exclaim_freq', 'mention_count', 'cap_freq']\n"
     ]
    }
   ],
   "source": [
    "features_col = [\n",
    "    col for col in data.columns \n",
    "    if (\n",
    "        (col.startswith(\"weekday\") or \n",
    "        #  col.startswith(\"count\") or \n",
    "         col.startswith(\"tfidf\")\n",
    "         ) and col != \"target\")\n",
    "]\n",
    "\n",
    "other_features = [\"exclaim_freq\", \"mention_count\", \"cap_freq\"]\n",
    "features_col += other_features\n",
    "print(\"Non-token features:\")\n",
    "print([col for col in features_col if not (col.startswith(\"count\") or col.startswith(\"tfidf\"))])\n",
    "\n",
    "XX = data[features_col]\n",
    "yy = data[[\"target\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking with BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "X_input = X_train\n",
    "bnb.fit(X_input, y_train)\n",
    "y_pred = bnb.predict(\n",
    "    X_test\n",
    ")\n",
    "\n",
    "def assess(y_true, y_pred):\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"accuracy_score:\")\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    print()\n",
    "\n",
    "# print(\"confusion matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print()\n",
    "# print(\"accuracy_score:\")\n",
    "# print(accuracy_score(y_test, y_pred))\n",
    "# print()\n",
    "# print(\"classification report:\")\n",
    "# print(classification_report(y_test,y_pred))\n",
    "# print()\n",
    "assess(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "X_input = X_train\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_features': [\n",
    "        'sqrt', \n",
    "        'log2', \n",
    "        # None\n",
    "    ],\n",
    "    'max_depth': [10, 50, 100],\n",
    "    # 'max_leaf_nodes': [3, 6, 9],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(),\n",
    "                           param_grid=param_grid, verbose=4)\n",
    "grid_search.fit(X_input, y_train)\n",
    "\n",
    "rfc = grid_search.best_estimator_\n",
    "print(rfc)\n",
    "rfc.fit(X_input, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_input, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(y_true, y_pred):\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"accuracy_score:\")\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    print()\n",
    "\n",
    "assess(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "feature_names = rfc.feature_names_in_\n",
    "importances = rfc.feature_importances_\n",
    "idx = np.argsort(importances)\n",
    "feature_names[idx][-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hisky\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737\n",
      "confusion matrix:\n",
      "[[333 142]\n",
      " [121 404]]\n",
      "\n",
      "accuracy_score:\n",
      "0.737\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.72       475\n",
      "           4       0.74      0.77      0.75       525\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_input = X_train\n",
    "\n",
    "logit_reg = LogisticRegression(max_iter=1000)\n",
    "logit_reg.fit(X_input, y_train)\n",
    "\n",
    "y_pred = logit_reg.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "y_pred_prob=logit_reg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "def assess(y_true, y_pred):\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"accuracy_score:\")\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    print()\n",
    "\n",
    "assess(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
